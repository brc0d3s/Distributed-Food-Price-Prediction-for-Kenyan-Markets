{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "35ubfEvC47RS"
   },
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/15 04:15:33 WARN Utils: Your hostname, codespaces-ebd91c resolves to a loopback address: 127.0.0.1; using 10.0.1.23 instead (on interface eth0)\n",
      "25/04/15 04:15:33 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/04/15 04:15:33 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/04/15 04:15:34 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'FoodPricePrediction'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('FoodPricePrediction').master('local[*]').getOrCreate()\n",
    "\n",
    "spark.sparkContext.appName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mqHYFiUkG-g5"
   },
   "outputs": [],
   "source": [
    "path = \"data/FoodPriceData\"\n",
    "food_price_data = spark.read.csv(path, inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1744619226799,
     "user": {
      "displayName": "BRIAN OMONDI",
      "userId": "10412797874550437401"
     },
     "user_tz": -180
    },
    "id": "-zgCExo16PYw",
    "outputId": "4c804f29-ffb3-45e2-83f4-b19183e1f698"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----+-------+--------+--------+------------------+-------------+-----+---------+------+---------------+----------------+--------------------+\n",
      "|year|month| region|  county|  market|          category|    commodity| unit|pricetype| price|avg_rainfall_mm|normalized_price|log_normalized_price|\n",
      "+----+-----+-------+--------+--------+------------------+-------------+-----+---------+------+---------------+----------------+--------------------+\n",
      "|2014|    1|  Coast| Mombasa| Mombasa|cereals and tubers|        Maize|   KG|Wholesale| 38.44|         259.33|           38.44|  3.6747805297344347|\n",
      "|2014|    1|  Coast| Mombasa| Mombasa|   pulses and nuts|        Beans|   KG|Wholesale| 79.99|         259.33|           79.99|  4.3943256902608985|\n",
      "|2014|    1|  Coast| Mombasa| Mombasa|   pulses and nuts|  Beans (dry)|90 KG|Wholesale|5738.0|         259.33|           63.76|   4.170688128809434|\n",
      "|2014|    1|Eastern|   Kitui|   Kitui|   pulses and nuts|  Beans (dry)|   KG|   Retail|  74.0|         259.33|            74.0|    4.31748811353631|\n",
      "|2014|    1|Eastern|Marsabit|Marsabit|cereals and tubers|Maize (white)|   KG|   Retail| 53.36|         259.33|           53.36|   3.995628589282943|\n",
      "+----+-----+-------+--------+--------+------------------+-------------+-----+---------+------+---------------+----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "food_price_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nnDt1jX-4v0K"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml import PipelineModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XLI6D14QAw5r"
   },
   "outputs": [],
   "source": [
    "# Drop nulls from essential columns\n",
    "model_data = food_price_data.dropna(subset=[\n",
    "    \"region\", \"county\", \"market\", \"category\", \"commodity\", \"unit\", \"pricetype\",\n",
    "    \"log_normalized_price\", \"avg_rainfall_mm\"\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "VO0fRqD0HsAa"
   },
   "outputs": [],
   "source": [
    "# Index categorical columns\n",
    "categorical_cols = [\"region\", \"county\", \"market\", \"category\", \"commodity\", \"unit\", \"pricetype\"]\n",
    "indexers = [StringIndexer(inputCol=col, outputCol=col+\"_indexed\", handleInvalid=\"keep\") for col in categorical_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "r3nRPXBd4vvC"
   },
   "outputs": [],
   "source": [
    "# Assemble features\n",
    "feature_cols = [col+\"_indexed\" for col in categorical_cols] + [\"month\", \"year\", \"avg_rainfall_mm\"]\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "KDtAYJyn4vr6"
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "dt = DecisionTreeRegressor(featuresCol=\"features\", labelCol=\"log_normalized_price\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FxfiNkoQ4vn8"
   },
   "outputs": [],
   "source": [
    "# Build pipeline\n",
    "pipeline = Pipeline(stages=indexers + [assembler, dt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KN3imSJT4vlI"
   },
   "outputs": [],
   "source": [
    "# Split the data\n",
    "train_data, test_data = model_data.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_y2AF7tLKVCp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "g4ym6sW4TzC5"
   },
   "outputs": [],
   "source": [
    "# Evaluator\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"log_normalized_price\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"rmse\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "HIWcqMfCTy3w"
   },
   "outputs": [],
   "source": [
    "# Cross-validation with updated param grid\n",
    "paramGrid = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(dt.maxDepth, [5, 10])\n",
    "    .addGrid(dt.maxBins, [100])\n",
    "    .build()\n",
    ")\n",
    "\n",
    "cv = CrossValidator(\n",
    "    estimator=pipeline,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "MC5aeVN_4viC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/15 04:15:51 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "# Train model with CV\n",
    "cv_model = cv.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "RgcNjbCm__4U"
   },
   "outputs": [],
   "source": [
    "# Predict\n",
    "predictions = cv_model.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z-v9Y9Px__1w"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1744619252756,
     "user": {
      "displayName": "BRIAN OMONDI",
      "userId": "10412797874550437401"
     },
     "user_tz": -180
    },
    "id": "2pFw623h__y_",
    "outputId": "58337cf1-deb6-4258-da86-8f7f2485715e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-Validated RMSE: 0.24\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Cross-Validated RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kv3K9bhw__wn"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "vTkfBN2D__ud"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Save entire model pipeline\n",
    "cv_model.bestModel.write().overwrite().save(\"model/log_price_pipeline_model\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
